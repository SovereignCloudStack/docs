"use strict";(self.webpackChunkdocs=self.webpackChunkdocs||[]).push([[61976],{19186:(e,t,n)=>{n.r(t),n.d(t,{assets:()=>l,contentTitle:()=>a,default:()=>h,frontMatter:()=>r,metadata:()=>o,toc:()=>c});const o=JSON.parse('{"id":"scs-0119-v1-rook-decision","title":"Replacement of the deprecated ceph-ansible tool","description":"Abstract","source":"@site/standards/scs-0119-v1-rook-decision.md","sourceDirName":".","slug":"/scs-0119-v1-rook-decision","permalink":"/standards/scs-0119-v1-rook-decision","draft":false,"unlisted":false,"tags":[],"version":"current","frontMatter":{"title":"Replacement of the deprecated ceph-ansible tool","type":"Decision Record","status":"Draft","track":"IaaS"},"sidebar":"standards","previous":{"title":"scs-0119: Replacement of the deprecated ceph-ansible tool","permalink":"/standards/iaas/scs-0119"},"next":{"title":"scs-0120: Cluster-API images","permalink":"/standards/iaas/scs-0120"}}');var i=n(74848),s=n(28453);const r={title:"Replacement of the deprecated ceph-ansible tool",type:"Decision Record",status:"Draft",track:"IaaS"},a=void 0,l={},c=[{value:"Abstract",id:"abstract",level:2},{value:"Context",id:"context",level:2},{value:"Comparison of Features",id:"comparison-of-features",level:3},{value:"Feature Decision Table",id:"feature-decision-table",level:4},{value:"Evaluation in the Light of SCS Community Plans and Preferences",id:"evaluation-in-the-light-of-scs-community-plans-and-preferences",level:4},{value:"Decision",id:"decision",level:2},{value:"Consequences",id:"consequences",level:2}];function d(e){const t={a:"a",code:"code",h2:"h2",h3:"h3",h4:"h4",li:"li",p:"p",strong:"strong",table:"table",tbody:"tbody",td:"td",th:"th",thead:"thead",tr:"tr",ul:"ul",...(0,s.R)(),...e.components};return(0,i.jsxs)(i.Fragment,{children:[(0,i.jsx)(t.h2,{id:"abstract",children:"Abstract"}),"\n",(0,i.jsxs)(t.p,{children:["This decision record evaluates the choice for a modern, future-proof deployment tool for the networked storage solution Ceph in the SCS reference implementation, ",(0,i.jsx)(t.a,{href:"https://osism.tech/",children:"OSISM"}),".\nThe new deployment tool aims to enhance Kubernetes integration within SCS, potentially allowing providers to manage the Ceph cluster with greater ease and efficiency."]}),"\n",(0,i.jsx)(t.h2,{id:"context",children:"Context"}),"\n",(0,i.jsxs)(t.p,{children:["The current reference implementation relies on ",(0,i.jsx)(t.code,{children:"ceph-ansible"}),", ",(0,i.jsx)(t.a,{href:"https://github.com/ceph/ceph-ansible/commit/a9d1ec844d24fcc3ddea7c030eff4cd6c414d23d",children:"which is now deprecated"}),". As a result, this decision record evaluates two alternatives: ",(0,i.jsx)(t.a,{href:"https://docs.ceph.com/en/latest/cephadm/",children:"Cephadm"})," and ",(0,i.jsx)(t.a,{href:"https://rook.io/docs/rook/latest-release/Getting-Started/intro/",children:"Rook"}),"."]}),"\n",(0,i.jsxs)(t.p,{children:["Both tools are designed to roll out and configure Ceph clusters, providing the capability to manage clusters throughout their lifecycle. This includes functionalities such as adding or removing OSDs, upgrading Ceph services, and managing CRUSH maps, as outlined in the ",(0,i.jsx)(t.a,{href:"#feature-decision-table",children:"Feature-Decision-Table"}),"."]}),"\n",(0,i.jsx)(t.p,{children:"This decision record considers both the current and future needs of the reference implementation. The decision is guided by a comprehensive comparison of each tool's capabilities and limitations as well as the SCS communities needs and futures objectives."}),"\n",(0,i.jsx)(t.h3,{id:"comparison-of-features",children:"Comparison of Features"}),"\n",(0,i.jsx)(t.p,{children:"The tool selected in this decision MUST ensure:"}),"\n",(0,i.jsxs)(t.ul,{children:["\n",(0,i.jsx)(t.li,{children:"ease of migration"}),"\n",(0,i.jsx)(t.li,{children:"future-proofness"}),"\n",(0,i.jsx)(t.li,{children:"feature-completeness and feature-maturity"}),"\n",(0,i.jsx)(t.li,{children:"effective management of Ceph clusters"}),"\n"]}),"\n",(0,i.jsx)(t.h4,{id:"feature-decision-table",children:"Feature Decision Table"}),"\n",(0,i.jsx)(t.p,{children:"A comparative analysis of Cephadm and Rook highlights the following:"}),"\n",(0,i.jsxs)(t.table,{children:[(0,i.jsx)(t.thead,{children:(0,i.jsxs)(t.tr,{children:[(0,i.jsx)(t.th,{children:"Feature"}),(0,i.jsx)(t.th,{children:"Supported in Cephadm"}),(0,i.jsx)(t.th,{children:"Supported in Rook"})]})}),(0,i.jsxs)(t.tbody,{children:[(0,i.jsxs)(t.tr,{children:[(0,i.jsx)(t.td,{children:"Migrate from other setups"}),(0,i.jsxs)(t.td,{children:["\u2611 Adoption of clusters, that where built with ceph-ansible ",(0,i.jsx)(t.a,{href:"https://docs.ceph.com/en/quincy/cephadm/adoption/",children:"is officially supported"}),"."]}),(0,i.jsxs)(t.td,{children:["\u2610 Migration from other setups is not offically supported. See this ",(0,i.jsx)(t.a,{href:"https://github.com/rook/rook/discussions/12045",children:"issue"}),". Consequently, SCS develops a migration tool, named ",(0,i.jsx)(t.a,{href:"https://github.com/SovereignCloudStack/rookify",children:"rookify"}),". Alternatively, Rook allows to use ",(0,i.jsx)(t.a,{href:"https://rook.io/docs/rook/latest-release/CRDs/Cluster/external-cluster/external-cluster/",children:"Ceph as an external cluster"}),"."]})]}),(0,i.jsxs)(t.tr,{children:[(0,i.jsx)(t.td,{children:"Connect RGW with OpenStack Keystone"}),(0,i.jsx)(t.td,{children:"\u2611"}),(0,i.jsx)(t.td,{children:"\u2611 Experimental"})]}),(0,i.jsxs)(t.tr,{children:[(0,i.jsx)(t.td,{children:"Deploy specific Ceph versions"}),(0,i.jsx)(t.td,{children:"\u2611"}),(0,i.jsx)(t.td,{children:"\u2611"})]}),(0,i.jsxs)(t.tr,{children:[(0,i.jsx)(t.td,{children:"Upgrade to specific Ceph versions"}),(0,i.jsx)(t.td,{children:"\u2611 Streamlined upgrade process."}),(0,i.jsxs)(t.td,{children:["\u2611 Rook, CSI and Ceph upgrades have to be aligned, there is a ",(0,i.jsx)(t.a,{href:"https://rook.io/docs/rook/latest-release/Upgrade/health-verification/",children:"guide"})," available for each Rook version."]})]}),(0,i.jsxs)(t.tr,{children:[(0,i.jsx)(t.td,{children:"Deploy Ceph Monitors"}),(0,i.jsx)(t.td,{children:"\u2611"}),(0,i.jsx)(t.td,{children:"\u2611"})]}),(0,i.jsxs)(t.tr,{children:[(0,i.jsx)(t.td,{children:"Deploy Ceph Managers"}),(0,i.jsx)(t.td,{children:"\u2611"}),(0,i.jsx)(t.td,{children:"\u2611"})]}),(0,i.jsxs)(t.tr,{children:[(0,i.jsx)(t.td,{children:"Deploy Ceph OSDs"}),(0,i.jsx)(t.td,{children:"\u2611"}),(0,i.jsx)(t.td,{children:"\u2611"})]}),(0,i.jsxs)(t.tr,{children:[(0,i.jsx)(t.td,{children:"Deploy Ceph Object Gateway (RGW)"}),(0,i.jsx)(t.td,{children:"\u2611"}),(0,i.jsx)(t.td,{children:"\u2611"})]}),(0,i.jsxs)(t.tr,{children:[(0,i.jsx)(t.td,{children:"Removal of nodes"}),(0,i.jsx)(t.td,{children:"\u2611"}),(0,i.jsx)(t.td,{children:"\u2611"})]}),(0,i.jsxs)(t.tr,{children:[(0,i.jsx)(t.td,{children:"Purging of complete cluster"}),(0,i.jsx)(t.td,{children:"\u2611"}),(0,i.jsx)(t.td,{children:"\u2611"})]})]})]}),"\n",(0,i.jsx)(t.p,{children:"\u2610 not supported (yet)\n\u2611 supported\n\u2611\u2611 better option\n\u2612 not supported on purpose"}),"\n",(0,i.jsx)(t.h4,{id:"evaluation-in-the-light-of-scs-community-plans-and-preferences",children:"Evaluation in the Light of SCS Community Plans and Preferences"}),"\n",(0,i.jsxs)(t.p,{children:[(0,i.jsx)(t.strong,{children:"Environment"}),": Cephadm is better suited for traditional or standalone environments. Conversely, Rook is tailored for Kubernetes. That being said, it's important to note that the current state of resource deployment and management on Kubernetes within the IaaS reference implementation is still in its early stages. This would make Rook one of the first components to utilise Kubernetes in OSISM."]}),"\n",(0,i.jsxs)(t.p,{children:[(0,i.jsx)(t.strong,{children:"Deployment"}),": Cephadm uses containerization for Ceph components, whereas Rook fully embraces the Kubernetes ecosystem for deployment and management. Although containerization is already a core concept in the reference implementation, there is a strong push from the SCS community to adopt more Kubernetes."]}),"\n",(0,i.jsxs)(t.p,{children:[(0,i.jsx)(t.strong,{children:"Configuration and Management"}),": Rook offers a more straightforward experience for those already utilizing Kubernetes, leveraging Kubernetes' features for automation and scaling. In contrast, Cephadm grants finer control over Ceph components, albeit necessitating more manual intervention. In both cases, this is something that needs to be partly abstracted by the reference implementation."]}),"\n",(0,i.jsxs)(t.p,{children:[(0,i.jsx)(t.strong,{children:"Integration"}),": Rook provides better integration with cloud-native tools and environments, whereas Cephadm offers a more Ceph-centric management experience."]}),"\n",(0,i.jsxs)(t.p,{children:[(0,i.jsx)(t.strong,{children:"Migration"}),": Rook does not currently provide any migration support, while Cephadm does offer this capability. However, the SCS community is highly supportive of developing a migration tool (Rookify) for Rook, as this would enhance SCS's influence by offering the first migration solution specifically for Rook providers."]}),"\n",(0,i.jsxs)(t.p,{children:[(0,i.jsx)(t.strong,{children:"SCS Community"}),": An important factor in our decision is the preferences and direction of the SCS community and its providers. There is a noticeable trend towards increased use of Kubernetes within the community. This indicates a preference for deployment tools that integrate well with Kubernetes environments."]}),"\n",(0,i.jsxs)(t.p,{children:[(0,i.jsx)(t.strong,{children:"SCS Future Goals"}),": The SCS community is open to building tools that provide open-source, publicly available solutions beyond the scope of SCS. This openness to development efforts that address limitations of the chosen tools, such as Rook, is also a key consideration in our decision."]}),"\n",(0,i.jsx)(t.h2,{id:"decision",children:"Decision"}),"\n",(0,i.jsx)(t.p,{children:"As OSISM will increasingly focus on a Kubernetes-centric approach for orchestration in the near future, adopting Rook is a more suitable and standardized approach. Moreover, many service providers within the SCS community (including several who deploy OSISM) already have experience with Kubernetes. Regarding the missing OpenStack Keystone integration, we are confident that colleagues, who work on this issue, will provide a solution in a timely manner. We expect that deploying Ceph with Rook will simplify deployment and configuration form the outset.\nIn order to allow for a migration from existing Ceph installations to Rook, we decided to develop a migration tool (called Rookify) for the reference implementation. If the development of Rookify goes beyond the targeted scope of the reference implementation the tool will add value to the Ceph as well as the Rook community."}),"\n",(0,i.jsx)(t.h2,{id:"consequences",children:"Consequences"}),"\n",(0,i.jsx)(t.p,{children:"Migrating an existing Ceph environment onto Kubernetes, as well as bringing together existing but independent Ceph and Kubernetes environments, will become straight forward without much manual interference needed.\nLandscapes that currently do not deploy a Kubernetes cluster have to adapt and provide a Kubernetes cluster in the future."})]})}function h(e={}){const{wrapper:t}={...(0,s.R)(),...e.components};return t?(0,i.jsx)(t,{...e,children:(0,i.jsx)(d,{...e})}):d(e)}},28453:(e,t,n)=>{n.d(t,{R:()=>r,x:()=>a});var o=n(96540);const i={},s=o.createContext(i);function r(e){const t=o.useContext(s);return o.useMemo((function(){return"function"==typeof e?e(t):{...t,...e}}),[t,e])}function a(e){let t;return t=e.disableParentContext?"function"==typeof e.components?e.components(i):e.components||i:r(e.components),o.createElement(s.Provider,{value:t},e.children)}}}]);