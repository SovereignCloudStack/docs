"use strict";(self.webpackChunkdocs=self.webpackChunkdocs||[]).push([[96707],{76148:(e,n,t)=>{t.r(n),t.d(n,{assets:()=>l,contentTitle:()=>r,default:()=>h,frontMatter:()=>i,metadata:()=>o,toc:()=>d});const o=JSON.parse('{"id":"iaas/guides/operations-guide/openstack/tools/openstack-health-monitor","title":"Setting up OpenStack health monitor on Debian","description":"Kurt Garloff, 2024-02-20","source":"@site/docs/02-iaas/guides/operations-guide/openstack/tools/openstack-health-monitor.md","sourceDirName":"02-iaas/guides/operations-guide/openstack/tools","slug":"/iaas/guides/operations-guide/openstack/tools/openstack-health-monitor","permalink":"/docs/iaas/guides/operations-guide/openstack/tools/openstack-health-monitor","draft":false,"unlisted":false,"editUrl":"https://github.com/SovereignCloudStack/docs/tree/main/docs/02-iaas/guides/operations-guide/openstack/tools/openstack-health-monitor.md","tags":[],"version":"current","frontMatter":{"sidebar_label":"OpenStack Health Monitor"},"sidebar":"docs","previous":{"title":"Simple Stress","permalink":"/docs/iaas/guides/operations-guide/openstack/tools/simple-stress"},"next":{"title":"Cinder","permalink":"/docs/iaas/guides/operations-guide/openstack/cinder"}}');var s=t(74848),a=t(28453);const i={sidebar_label:"OpenStack Health Monitor"},r="Setting up OpenStack health monitor on Debian",l={},d=[{value:"Intro",id:"intro",level:2},{value:"Setting up the driver VM",id:"setting-up-the-driver-vm",level:2},{value:"Internal vs external monitoring",id:"internal-vs-external-monitoring",level:3},{value:"Unprivileged operation",id:"unprivileged-operation",level:3},{value:"Driver VM via openstack CLI",id:"driver-vm-via-openstack-cli",level:3},{value:"Configuring openstack CLI on the driver VM",id:"configuring-openstack-cli-on-the-driver-vm",level:3},{value:"Custom CA",id:"custom-ca",level:3},{value:"Your first <code>api_monitor.sh</code> iteration",id:"your-first-api_monitorsh-iteration",level:2},{value:"Resource impact and charging",id:"resource-impact-and-charging",level:3},{value:"Automating startup and cleanup",id:"automating-startup-and-cleanup",level:2},{value:"Changing parameters and restarting",id:"changing-parameters-and-restarting",level:3},{value:"Multiple instances",id:"multiple-instances",level:3},{value:"Alarming and Logs",id:"alarming-and-logs",level:2},{value:"eMail",id:"email",level:3},{value:"Log files",id:"log-files",level:3},{value:"Data collection and dashboard",id:"data-collection-and-dashboard",level:2},{value:"Telegraf",id:"telegraf",level:3},{value:"InfluxDB",id:"influxdb",level:3},{value:"Add <code>-S CLOUDNAME</code> to your <code>run_CLOUDNAME.sh</code> script",id:"add--s-cloudname-to-your-run_cloudnamesh-script",level:3},{value:"Caddy (Reverse Proxy)",id:"caddy-reverse-proxy",level:3},{value:"Install Caddy",id:"install-caddy",level:4},{value:"Allow HTTP traffic for oshm-driver",id:"allow-http-traffic-for-oshm-driver",level:4},{value:"Configure Caddy",id:"configure-caddy",level:4},{value:"Grafana",id:"grafana",level:3},{value:"Install Grafana",id:"install-grafana",level:4},{value:"Basic config",id:"basic-config",level:4},{value:"Enable influx database in grafana",id:"enable-influx-database-in-grafana",level:4},{value:"Importing the dashboard",id:"importing-the-dashboard",level:4},{value:"No data displayed?",id:"no-data-displayed",level:4},{value:"Dashboard features",id:"dashboard-features",level:4},{value:"GitHub OIDC Integration",id:"github-oidc-integration",level:4},{value:"Maintenance",id:"maintenance",level:2},{value:"Unattended upgrades",id:"unattended-upgrades",level:3},{value:"sshd setup",id:"sshd-setup",level:3},{value:"Updating openstack-health-monitor",id:"updating-openstack-health-monitor",level:3},{value:"Backup",id:"backup",level:3},{value:"Troubleshooting",id:"troubleshooting",level:2},{value:"Debugging issues",id:"debugging-issues",level:3},{value:"Analyzing failures",id:"analyzing-failures",level:3},{value:"Cleaning things up",id:"cleaning-things-up",level:3}];function c(e){const n={a:"a",code:"code",em:"em",h1:"h1",h2:"h2",h3:"h3",h4:"h4",header:"header",li:"li",ol:"ol",p:"p",pre:"pre",strong:"strong",ul:"ul",...(0,a.R)(),...e.components};return(0,s.jsxs)(s.Fragment,{children:[(0,s.jsx)(n.header,{children:(0,s.jsx)(n.h1,{id:"setting-up-openstack-health-monitor-on-debian",children:"Setting up OpenStack health monitor on Debian"})}),"\n",(0,s.jsx)(n.p,{children:"Kurt Garloff, 2024-02-20"}),"\n",(0,s.jsx)(n.h2,{id:"intro",children:"Intro"}),"\n",(0,s.jsxs)(n.p,{children:["The development of ",(0,s.jsx)(n.a,{href:"https://github.com/SovereignCloudStack/openstack-health-monitor/",children:"openstack-health-monitor"})," was done on ",(0,s.jsx)(n.a,{href:"https://kfg.images.obs-website.eu-de.otc.t-systems.com/",children:"openSUSE 15.x images"}),", just because the author is very familiar with it and has some of the needed tools preinstalled. That said, the setup is not depending on anything specific from openSUSE and should work on every modern Linux distribution."]}),"\n",(0,s.jsx)(n.p,{children:"Setting it up again in a different environment using Debian 12 images avoids a few of the shortcuts that were used and thus should be very suitable instructions to get it working in general. The step by step instructions are covered here."}),"\n",(0,s.jsxs)(n.p,{children:["Note: This is a rather classical snowflake setup -- we create a VM and do some manual configuration to get everything configured. Having it well documented here should make this more replicatable, and is an important precondition for more automation, but larger steps to full automate this using ansible or helm charts (in a containerized variant) are not addressed here. As we expect a ",(0,s.jsx)(n.a,{href:"https://github.com/SovereignCloudStack/scs-health-monitor",children:"successor project"})," for the increasingly hard to maintain shell code, this may not be worth the trouble."]}),"\n",(0,s.jsxs)(n.p,{children:["openstack-health-monitor implements a scripted scenario test with a large shell-script that uses the openstackclient tools to set up the scenario, test it and tear everything down again in a loop. Any errors are recorded, as well as timings and some very basic benchmarks. The script sets up some virtual network infrastructure (routers, networks, subnets, floating IPs), security groups, keypairs, volumes and finally boots some VMs. Access to these is tested (ensuring metadata injection works) and connectivity between them tested and measured. A loadbalancer (optionally) is set up with a health-monitor and access via it before and after killing some backends is tested.\nThe scenario is described in a bit more detail in the ",(0,s.jsx)(n.a,{href:"https://github.com/SovereignCloudStack/openstack-health-monitor/blob/main/README.md",children:"repository's README.md"})," file."]}),"\n",(0,s.jsxs)(n.p,{children:["The openstack-health-monitor is not the intended long-term solution for monitoring your infrastructure. The SCS project has a project underway that will create more modern, flexible, and more maintainable monitoring infrastructure; the concepts are described on the ",(0,s.jsx)(n.a,{href:"https://docs.scs.community/docs/category/monitoring",children:"monitoring section"})," of the project's documentation. The openstack-health-monitor will thus not see any significant enhancements any more; it will be maintained and kept alive as long as there are users. This guide exclusively focuses on how to set it up."]}),"\n",(0,s.jsx)(n.h2,{id:"setting-up-the-driver-vm",children:"Setting up the driver VM"}),"\n",(0,s.jsxs)(n.p,{children:["So we start a ",(0,s.jsx)(n.code,{children:"Debian 12"})," image on a cloud of our choice. This should work on any OpenStack cloud that is reasonably standard;\nthe instructions use flavor names and image names from the SCS standards.\nFor many, the simplest way may be to use the Web-UI of their cloud (e.g. horizon for OpenStack)."]}),"\n",(0,s.jsx)(n.h3,{id:"internal-vs-external-monitoring",children:"Internal vs external monitoring"}),"\n",(0,s.jsx)(n.p,{children:"There are pros and cons to run the driver VM in the same cloud that is also under test. We obviously don't test the external reachability of the cloud (more precisely its API endpoints and VMs) if we run it on the same cloud -- which may or may not be desirable. Having the tests happily continuing to collect data  may actually be valuable in times when external access is barred. If the cloud goes down, we will no longer see API calls against it, although the information of them not being available does not reveal much in terms of insight into the reasons for the outage. Also, the driver VM is the only long-lived VM in the openstack-health-monitor setup, so it may be useful to have it in the same cloud to reveal any issues that do not occur on the short-lived resources created and deleted by the health-monitor."}),"\n",(0,s.jsx)(n.p,{children:"The author tends to see running it internally as advantageous -- ideally combined with a simple API reachability test from the outside that sends alarms as needed to detect any reachability problems."}),"\n",(0,s.jsx)(n.h3,{id:"unprivileged-operation",children:"Unprivileged operation"}),"\n",(0,s.jsx)(n.p,{children:"Nothing in this test requires admin privileges on the cloud where the driver runs nor on the cloud under test. We do install and configure a few software packages in the driver VM, which requires sudo power there, but the script should just run as a normal user. For the cloud under test it is recommended to use a user (or an application credential) with a normal tenant member role to access the cloud under test. If you can, give it an OpenStack project on its own."}),"\n",(0,s.jsxs)(n.p,{children:["If ",(0,s.jsx)(n.code,{children:"openstack availability zone list --compute"})," fails for you without admin rights, please fix your openstack client, e.g. by applying the ",(0,s.jsx)(n.a,{href:"https://raw.githubusercontent.com/SovereignCloudStack/openstack-health-monitor/main/docs/openstackclient-az-list-fallback-f3207bd.diff",children:"patch"})," I mentioned in ",(0,s.jsx)(n.a,{href:"https://storyboard.openstack.org/#!/story/2010989",children:"this issue"}),". (Versions 6.3.0 and 6.4.0 are broken.) Do not consider giving the OpenStack Health-Monitor admin power. (Note: It has a workaround for the broken AZ listing using curl now.)"]}),"\n",(0,s.jsx)(n.h3,{id:"driver-vm-via-openstack-cli",children:"Driver VM via openstack CLI"}),"\n",(0,s.jsxs)(n.p,{children:["The author prefers to setup the VM via ",(0,s.jsx)(n.code,{children:"openstack"})," CLI tooling. He has working entries for all clouds he uses in his ",(0,s.jsx)(n.code,{children:"~/.config/openstack/clouds.yaml"})," and ",(0,s.jsx)(n.code,{children:"secure.yaml"})," and has exported the ",(0,s.jsx)(n.code,{children:"OS_CLOUD"})," environment variable to point to the cloud he is working on to set up the driver VM. The author uses the ",(0,s.jsx)(n.code,{children:"bash"})," shell. All of this of course could be scripted."]}),"\n",(0,s.jsx)(n.p,{children:"So here we go"}),"\n",(0,s.jsxs)(n.ol,{children:["\n",(0,s.jsxs)(n.li,{children:["Create the network setup for a VM in a network ",(0,s.jsx)(n.code,{children:"oshm-network"})," with an IPv4 subnet, connected to a router that connects (and by default SNATs) to the public network."]}),"\n"]}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-bash",children:"PUBLIC=$(openstack network list --external -f value -c Name)\nopenstack router create oshm-router\nopenstack router set --external-gateway $PUBLIC oshm-driver-router\nopenstack network create oshm-network\nopenstack subnet create --subnet-range 192.168.192.0/24 --network oshm-network oshm-subnet\nopenstack router add subnet oshm-router oshm-subnet\n"})}),"\n",(0,s.jsxs)(n.ol,{start:"2",children:["\n",(0,s.jsx)(n.li,{children:"Create a security group that allows ssh and ping access"}),"\n"]}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-bash",children:"openstack security group create sshping\nopenstack security group rule create --ingress --ethertype ipv4 --protocol tcp --dst-port 22 sshping\nopenstack security group rule create --ingress --ethertype ipv4 --protocol icmp --icmp-type 8 sshping\n"})}),"\n",(0,s.jsxs)(n.ol,{start:"3",children:["\n",(0,s.jsx)(n.li,{children:"Being at it, we also create the security group for grafana"}),"\n"]}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-bash",children:"openstack security group create grafana\nopenstack security group rule create --ingress --ethertype ipv4 --protocol tcp --dst-port 3000 grafana\n"})}),"\n",(0,s.jsxs)(n.ol,{start:"4",children:["\n",(0,s.jsx)(n.li,{children:"To connect to the VM via ssh later, we create an SSH keypair"}),"\n"]}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-bash",children:"openstack keypair create --private-key ~/.ssh/oshm-key.pem oshm-key\nchmod og-r ~/.ssh/oshm-key.pem\n"})}),"\n",(0,s.jsxs)(n.p,{children:["Rather than creating a new key (and storing and protecting the private key), we could have passed ",(0,s.jsx)(n.code,{children:"--public-key"})," and used an existing keypair."]}),"\n",(0,s.jsxs)(n.ol,{start:"5",children:["\n",(0,s.jsx)(n.li,{children:"Look up Debian 12 image UUID."}),"\n"]}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-bash",children:"IMGUUID=$(openstack image list --name \"Debian 12\" -f value -c ID | tr -d '\\r')\necho $IMGUUID\n"})}),"\n",(0,s.jsxs)(n.p,{children:["Sidenote: The ",(0,s.jsx)(n.code,{children:"tr"})," command is there to handle broken tooling that embeds a trailing ",(0,s.jsx)(n.code,{children:"\\r"})," in the output."]}),"\n",(0,s.jsxs)(n.ol,{start:"6",children:["\n",(0,s.jsx)(n.li,{children:"Boot the driver VM"}),"\n"]}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-bash",children:"openstack server create --network oshm-network --key-name oshm-key --security-group default --security-group sshping --security-group grafana --flavor SCS-2V-4 --block-device boot_index=0,uuid=$IMGUUID,source_type=image,volume_size=10,destination_type=volume,delete_on_termination=true oshm-driver\n"})}),"\n",(0,s.jsxs)(n.p,{children:["Chose a flavor that exists on your cloud. Here we have used  one without root disk and asked nova to create a volume on the fly by passing ",(0,s.jsx)(n.code,{children:"--block-device"}),". See ",(0,s.jsx)(n.a,{href:"https://scs.community/2023/08/21/diskless-flavors/",children:"diskless flavor blog article"}),". For flavors with local root disks, you could have used the ",(0,s.jsx)(n.code,{children:"--image $IMGUUID"})," parameter instead."]}),"\n",(0,s.jsxs)(n.ol,{start:"7",children:["\n",(0,s.jsxs)(n.li,{children:["Wait for it to boot (optional)\nYou can look at the boot log with ",(0,s.jsx)(n.code,{children:"openstack console log show oshm-driver"})," or connect to it via VNC at the URL given by ",(0,s.jsx)(n.code,{children:"openstack console url show oshm-driver"}),". You can of course also query openstack on the status ",(0,s.jsx)(n.code,{children:"openstack server list"})," or ",(0,s.jsx)(n.code,{children:"openstack server show oshm-driver"}),". You can also just create a simple loop:"]}),"\n"]}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-bash",children:'declare -i ctr=0 RC=0\nwhile [ $ctr -le 120 ]; do\n  STATUS="$(openstack server list --name oshm-driver -f value -c Status)"\n  if [ "$STATUS" = "ACTIVE" ]; then echo "$STATUS"; break; fi\n  if [ "$STATUS" = "ERROR" ]; then echo "$STATUS"; RC=1; break; fi\n  if [ -z "$STATUS" ]; then echo "No such VM"; RC=2; break; fi\n  sleep 2\n  let ctr+=1\ndone\n# return $RC\nif [ $RC != 0 ]; then false; fi\n'})}),"\n",(0,s.jsxs)(n.ol,{start:"8",children:["\n",(0,s.jsx)(n.li,{children:"Attach a floating IP so it's reachable from the outside."}),"\n"]}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-bash",children:'FIXEDIP=$(openstack server list --name oshm-driver -f value -c Networks |  sed "s@^[^:]*:[^\']*\'\\([0-9\\.]*\\)\'.*\\$@\\1@")\nFIXEDPORT=$(openstack port list --fixed-ip ip-address=$FIXEDIP,subnet=oshm-subnet -f value -c ID)\necho $FIXEDIP $FIXEDPORT\nopenstack floating ip create --port $FIXEDPORT $PUBLIC\nFLOATINGIP=$(openstack floating ip list --fixed-ip-address $FIXEDIP -f value -c "Floating IP Address")\necho "Floating IP: $FLOATINGIP"\n'})}),"\n",(0,s.jsx)(n.p,{children:"Remember this floating IP address."}),"\n",(0,s.jsxs)(n.ol,{start:"9",children:["\n",(0,s.jsx)(n.li,{children:"Connect to it via ssh"}),"\n"]}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-bash",children:"ssh -i ~/.ssh/oshm-key.pem debian@$FLOATINGIP\n"})}),"\n",(0,s.jsx)(n.p,{children:"On the first connection, you need to accept the new ssh host key. (Very careful people would compare the fingerprint with the console log output.)"}),"\n",(0,s.jsx)(n.p,{children:(0,s.jsx)(n.strong,{children:"All the following commands are performed on the newly started driver VM."})}),"\n",(0,s.jsx)(n.h3,{id:"configuring-openstack-cli-on-the-driver-vm",children:"Configuring openstack CLI on the driver VM"}),"\n",(0,s.jsx)(n.p,{children:"We need to install the openstack client utilities."}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-bash",children:"sudo apt-get update\nsudo apt-get install python3-openstackclient\nsudo apt-get install python3-cinderclient python3-octaviaclient python3-swiftclient python3-designateclient\n"})}),"\n",(0,s.jsxs)(n.p,{children:["Configure your cloud access in ",(0,s.jsx)(n.code,{children:"~/.config/openstack/clouds.yaml"})]}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-yaml",children:"clouds:\n  CLOUDNAME:\n    interface: public\n    identity-api-version: 3\n    #region_name: REGION\n    auth:\n      auth_url: KEYSTONE_ENDPOINT\n      project_id: PROJECT_UUID\n      #alternatively project_name and project_domain_name\n      user_domain_name: default\n      # change to your real domain\n"})}),"\n",(0,s.jsxs)(n.p,{children:["and ",(0,s.jsx)(n.code,{children:"secure.yaml"})," (in the same directory)"]}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-yaml",children:"clouds:\n  CLOUDNAME:\n    auth:\n      username: USERNAME\n      password: PASSWORD\n"})}),"\n",(0,s.jsxs)(n.p,{children:["The ",(0,s.jsx)(n.code,{children:"CLOUDNAME"})," can be freely chosen. This is the value passed to the openstack CLI with ",(0,s.jsx)(n.code,{children:"--os-cloud"})," or exported to your environment in ",(0,s.jsx)(n.code,{children:"OS_CLOUD"}),". The other uppercase words need to be adjusted to match your cloud. Hint: horizon typically lets you download a sample ",(0,s.jsx)(n.code,{children:"clouds.yaml"})," file that works (but lacks the password)."]}),"\n",(0,s.jsxs)(n.p,{children:["Protect your ",(0,s.jsx)(n.code,{children:"secure.yaml"})," from being read by others: ",(0,s.jsx)(n.code,{children:"chmod 0600 ~/.config/openstack/secure.yaml"}),"."]}),"\n",(0,s.jsxs)(n.p,{children:["If you are using application credentials instead of username, password to authenticate, you don't need to specify ",(0,s.jsx)(n.code,{children:"project_id"})," nor project's nor user's domain names in ",(0,s.jsx)(n.code,{children:"clouds.yaml"}),". Just (in ",(0,s.jsx)(n.code,{children:"secure.yaml"}),"):"]}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-yaml",children:'clouds:\n  CLOUDNAME:\n    auth_type: v3applicationcredential\n    auth:\n      application_credential_id: APPCRED_ID\n      application_credential_secret: "APPCRED_SECRET"\n'})}),"\n",(0,s.jsx)(n.p,{children:"Configure this to be your default cloud:"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-bash",children:"export OS_CLOUD=CLOUDNAME\n"})}),"\n",(0,s.jsxs)(n.p,{children:["You might consider adding this to your ",(0,s.jsx)(n.code,{children:"~/.bashrc"})," for convenience. Being at it, you might want to add ",(0,s.jsx)(n.code,{children:"export CLIFF_FIT_WIDTH=1"})," there as well to make openstack command output tables more readable (but sometimes less easy to cut'n'paste)."]}),"\n",(0,s.jsx)(n.p,{children:"Verify that your openstack CLI works:"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-bash",children:"openstack catalog list\nopenstack server list\n"})}),"\n",(0,s.jsx)(n.p,{children:"You can use the same project as you use for your driver VM (and possibly other workloads). The openstack-health-monitor is carefully designed to not clean up anything that it has not created. There is however some trickiness, as not all resources have names (floating IPs for example do not) and sometimes names need to be assigned after creation of a resource (volumes of diskless flavors), so in case there are API errors, some heuristics is used to identify resources which may not be safe under all circumstances. So ideally, you have an extra project created just for the health-monitor and configure the credentials for it here, so you can not possibly hit any wrong resource in the script's extensive efforts to clean up in error cases."}),"\n",(0,s.jsx)(n.h3,{id:"custom-ca",children:"Custom CA"}),"\n",(0,s.jsxs)(n.p,{children:["If your cloud API's endpoints don't use TLS certificates that are signed by an official CA, you need to provide your CA to this VM and configure it. (On a SCS Cloud-in-a-Box system, you find it on the manager node in ",(0,s.jsx)(n.code,{children:"/etc/ssl/certs/ca-certificates.crt"}),". You may extract the last cert or just leave them all together.) Copy the CA file to your driver VM and ensure it's readable by the ",(0,s.jsx)(n.code,{children:"debian"})," user."]}),"\n",(0,s.jsxs)(n.p,{children:["Add it to your ",(0,s.jsx)(n.code,{children:"clouds.yaml"})]}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-yaml",children:"clouds:\n  CLOUDNAME:\n    cacert: /PATH/TO/CACERT.CRT\n    [...]\n"})}),"\n",(0,s.jsxs)(n.p,{children:["If you want to allow ",(0,s.jsx)(n.code,{children:"api_monitor.sh"})," to be able to talk to the service endpoints directly to avoid getting a fresh token from keystone for each call, you also need to export it to your environment:"]}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-bash",children:"export OS_CACERT=/PATH/TO/CACERT.CRT\n"})}),"\n",(0,s.jsxs)(n.p,{children:["Consider adding this to your ",(0,s.jsx)(n.code,{children:"~/.bashrc"})," as well."]}),"\n",(0,s.jsxs)(n.h2,{id:"your-first-api_monitorsh-iteration",children:["Your first ",(0,s.jsx)(n.code,{children:"api_monitor.sh"})," iteration"]}),"\n",(0,s.jsx)(n.p,{children:"Checkout openstack-health-monitor:"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-bash",children:"sudo apt-get install git bc jq netcat-traditional tmux zstd\ngit clone https://github.com/SovereignCloudStack/openstack-health-monitor\ncd openstack-health-monitor\n"})}),"\n",(0,s.jsxs)(n.p,{children:["You may want to start a ",(0,s.jsx)(n.code,{children:"tmux"})," (or ",(0,s.jsx)(n.code,{children:"screen"}),") session now, so you can do multiple things in parallel (e.g. for debugging) and reconnect."]}),"\n",(0,s.jsxs)(n.p,{children:["The script ",(0,s.jsx)(n.code,{children:"api_monitor.sh"})," is the main worker of openstack-health-monitor and runs one to many iterations of a cycle where resources are created, tested and torn down. Its operation is described in the ",(0,s.jsx)(n.a,{href:"https://github.com/SovereignCloudStack/openstack-health-monitor/blob/main/README.md",children:"README.md"})," file."]}),"\n",(0,s.jsxs)(n.p,{children:["It is good practice to use ",(0,s.jsx)(n.code,{children:"tmux"}),". This allows you to return (reattach) to console sessions and to open new windows to investigate things. Traditional people may prefer to ",(0,s.jsx)(n.code,{children:"screen"})," over ",(0,s.jsx)(n.code,{children:"tmux"}),"."]}),"\n",(0,s.jsx)(n.p,{children:"You should be ready to run one iteration of the openstack-health-monitor now. Run it like this:"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-bash",children:'export IMG="Debian 12"\nexport JHIMG="Debian 12"\n./api_monitor.sh -O -C -D -n 6 -s -b -B -M -T -LL -i 1\n'})}),"\n",(0,s.jsxs)(n.p,{children:["Leave out the ",(0,s.jsx)(n.code,{children:"-LL"})," if you don't have a working loadbalancer service or replace ",(0,s.jsx)(n.code,{children:"-LL"})," with ",(0,s.jsx)(n.code,{children:"-LO"})," if you want to test the ovn loadbalancer instead of amphorae (saving quite some resources)."]}),"\n",(0,s.jsxs)(n.p,{children:["Feel free to study the meaning of all the command line parameters by looking at the ",(0,s.jsx)(n.a,{href:"https://github.com/SovereignCloudStack/openstack-health-monitor/blob/main/README.md",children:"README.md"}),". (Note: Many of the things enabled by the parameters should be default, but are not for historic reasons. This would change if we rewrite this whole thing in python.)"]}),"\n",(0,s.jsxs)(n.p,{children:["This will run for ~7 minutes, depending on the performance of your OpenStack environment. You should not get any error. (The amber-colored outputs ",(0,s.jsx)(n.code,{children:"DOWN"}),", ",(0,s.jsx)(n.code,{children:"BUILD"}),", ",(0,s.jsx)(n.code,{children:"creating"})," are not errors. Nothing in red should be displayed.) Studying the console output may be instructive to follow the script's progress. You may also open another window (remember the tmux recommendation above) and look at the resources with the usual ",(0,s.jsx)(n.code,{children:"openstack RESOURCE list"})," and ",(0,s.jsx)(n.code,{children:"openstack RESOURCE show NAME"})," and ",(0,s.jsx)(n.code,{children:"RESOURCE"})," being something like ",(0,s.jsx)(n.code,{children:"router"}),", ",(0,s.jsx)(n.code,{children:"network"}),", ",(0,s.jsx)(n.code,{children:"subnet"}),", ",(0,s.jsx)(n.code,{children:"port"}),", ",(0,s.jsx)(n.code,{children:"volume"}),", ",(0,s.jsx)(n.code,{children:"server"}),", ",(0,s.jsx)(n.code,{children:"floating ip"}),", ",(0,s.jsx)(n.code,{children:"loadbalancer"}),", ",(0,s.jsx)(n.code,{children:"loadbalancer pool"}),", ",(0,s.jsx)(n.code,{children:"loadbalancer listener"}),", ",(0,s.jsx)(n.code,{children:"security group"}),", ",(0,s.jsx)(n.code,{children:"keypair"}),", ",(0,s.jsx)(n.code,{children:"image"}),", ...)"]}),"\n",(0,s.jsxs)(n.p,{children:["The ",(0,s.jsx)(n.code,{children:"api_monitor.sh"})," uses and ",(0,s.jsx)(n.code,{children:"APIMonitor_TIMESTAMP"})," prefix for all OpenStack resource names. This allows to identify the created resources and clean them up even if things go wrong.\n",(0,s.jsx)(n.code,{children:"TIMESTAMP"})," is an integer number representing the seconds after 1970-01-01 00:00:00 UTC (Unix time)."]}),"\n",(0,s.jsxs)(n.p,{children:["This may be the time to check that you have sufficient quota to create the resources. While we only create 6+N VMs (and volumes) with the above call (N being the number of AZs), we would want to increase this number for larger clouds. For single-AZ deployments, we would want to still use 2 networks at least ",(0,s.jsx)(n.code,{children:"-N 2"})," to test the ability of the router to route traffic between networks. So expect ",(0,s.jsx)(n.code,{children:"-n 6"})," to become ",(0,s.jsx)(n.code,{children:"-N 2 -n 6"})," for a very small single-AZ cloud or ",(0,s.jsx)(n.code,{children:"-n 12"})," for a large 3 AZ cloud region. So, re-run the ",(0,s.jsx)(n.code,{children:"api_monitor.sh"})," with the target sizing."]}),"\n",(0,s.jsx)(n.h3,{id:"resource-impact-and-charging",children:"Resource impact and charging"}),"\n",(0,s.jsxs)(n.p,{children:["Note that ",(0,s.jsx)(n.code,{children:"api_monitor.sh"})," uses small flavors (",(0,s.jsx)(n.code,{children:"SCS-1V-2"})," for the N jump hosts and ",(0,s.jsx)(n.code,{children:"SCS-1L-1"})," for the other VMs) to keep the impact on your cloud (and on your invoice if you are not monitoring your own cloud) small. You can change the flavors."]}),"\n",(0,s.jsxs)(n.p,{children:["If you have to pay for this, also consider that some clouds are not charging by the minute but may count by the started hour. So when you run ",(0,s.jsx)(n.code,{children:"api_monitor.sh"})," in a loop (which you will) with say 10 VMs (e.g. ",(0,s.jsx)(n.code,{children:"-N 2 -n 8"}),") in each iteration and run this for an hour with 8 iterations, you will never have more than 10 VMs in parallel and they only are alive a bit more than half of the time, but rather than being charged for ~6 VM hours, you end up being charged for ~80 VM hours. Similar for volumes, routers, floating IPs. This makes a huge difference."]}),"\n",(0,s.jsxs)(n.p,{children:["Sometimes the cloud under test has issues. That's why we do monitoring ... One thing that might happen is that loadbalancers and volumes (and other resources, but those two are the most prone to this) end up in a broken state that can not be cleaned up by the user any more. Bad providers may charge for these anyhow, although this will never stand a legal dispute. (IANAL, but charging for providing something that is not working is not typically supported by civil law in most jurisdictions and T&Cs that would say so would not normally be legally enforceable.) If this happens, I recommend to keep records of the broken state (store the output of ",(0,s.jsx)(n.code,{children:"openstack volume list"}),", ",(0,s.jsx)(n.code,{children:"openstack volume show BROKEN_VOLUME"}),", ",(0,s.jsx)(n.code,{children:"openstack loadbalancer list"}),", ",(0,s.jsx)(n.code,{children:"openstack loadbalancer show BROKEN_LB"}),".)"]}),"\n",(0,s.jsxs)(n.p,{children:["Using ",(0,s.jsx)(n.code,{children:"-w -1"})," makes ",(0,s.jsx)(n.code,{children:"api_monitor.sh"})," wait for interactive input whenever an error occurs; this can be convenient for debugging."]}),"\n",(0,s.jsx)(n.p,{children:"Once you have single iterations working nicely, we can proceed."}),"\n",(0,s.jsx)(n.h2,{id:"automating-startup-and-cleanup",children:"Automating startup and cleanup"}),"\n",(0,s.jsxs)(n.p,{children:["Typically, we run ",(0,s.jsx)(n.code,{children:"api_monitor.sh"})," with a limited amount of iterations (200) and then restart it. For each restart, we also output some statistics, compress the log file and look at any leftovers that did not get cleaned up. The latter happens in the start script that we create here."]}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-bash",children:'#!/bin/bash\n# run_CLOUDNAME.sh\n# Do some global settings\nexport IMG="Debian 12"\nexport JHIMG="Debian 12"\n#export OS_CACERT=/home/debian/ca-certificates.pem\n# Additional settings to override flavors or to\n# configure email addresses for sending alarms can be set here\n\n# Does openstack CLI work?\nopenstack server list >/dev/null || exit 1\n# Upload log files to this swift container (which you need to create)\n#export SWIFTCONTAINER=OS-HM-Logfiles\n\n# CLEANUP\necho "Finding resources from previous runs to clean up ..."\n# Find Floating IPs\nFIPLIST=""\nFIPS=$(openstack floating ip list -f value -c ID)\nfor fip in $FIPS; do\n        FIP=$(openstack floating ip show $fip | grep -o "APIMonitor_[0-9]*")\n        if test -n "$FIP"; then FIPLIST="${FIPLIST}${FIP}_\n"; fi\ndone\nFIPLIST=$(echo "$FIPLIST" | grep -v \'^$\' | sort -u)\n# Cleanup previous interrupted runs\nSERVERS=$(openstack server  list | grep -o "APIMonitor_[0-9]*_" | sort -u)\nKEYPAIR=$(openstack keypair list | grep -o "APIMonitor_[0-9]*_" | sort -u)\nVOLUMES=$(openstack volume  list | grep -o "APIMonitor_[0-9]*_" | sort -u)\nNETWORK=$(openstack network list | grep -o "APIMonitor_[0-9]*_" | sort -u)\nLOADBAL=$(openstack loadbalancer list | grep -o "APIMonitor_[0-9]*_" | sort -u)\nROUTERS=$(openstack router  list | grep -o "APIMonitor_[0-9]*_" | sort -u)\nSECGRPS=$(openstack security group list | grep -o "APIMonitor_[0-9]*_" | sort -u)\necho CLEANUP: FIPs $FIPLIST Servers $SERVERS Keypairs $KEYPAIR Volumes $VOLUMES Networks $NETWORK LoadBalancers $LOADBAL Routers $ROUTERS SecGrps $SECGRPS\nfor ENV in $FIPLIST; do\n  echo "******************************"\n  echo "CLEAN $ENV"\n  bash ./api_monitor.sh -o -T -q -c CLEANUP $ENV\n  echo "******************************"\ndone\nTOCLEAN=$(echo "$SERVERS\n$KEYPAIR\n$VOLUMES\n$NETWORK\n$LOADBAL\n$ROUTERS\n$SECGRPS\n" | grep -v \'^$\' | sort -u)\nfor ENV in $TOCLEAN; do\n  echo "******************************"\n  echo "CLEAN $ENV"\n  bash ./api_monitor.sh -o -q -LL -c CLEANUP $ENV\n  echo "******************************"\ndone\n\n# Now run the monitor\n#exec ./api_monitor.sh -O -C -D -N 2 -n 6 -s -M -LO -b -B -a 2 -t -T -R -S ciab "$@"\nexec ./api_monitor.sh -O -C -D -N 2 -n 6 -s -M -LO -b -B -T "$@"\n'})}),"\n",(0,s.jsxs)(n.p,{children:["Compared to the previous run, we have explicitly set two networks here ",(0,s.jsx)(n.code,{children:"-N 2"})," and rely on the iterations being passed in as command line arguments. Add parameter ",(0,s.jsx)(n.code,{children:"-t"})," if your cloud is slow to increase timeouts. We have enabled the octavia loadbalancer (",(0,s.jsx)(n.code,{children:"-LO"}),") in this example rather than the amphora based one (",(0,s.jsx)(n.code,{children:"-LL"}),")."]}),"\n",(0,s.jsxs)(n.p,{children:["You may use one of the existing ",(0,s.jsx)(n.code,{children:"run_XXXX.sh"})," scripts as example. Beware: eMail alerting with ",(0,s.jsx)(n.code,{children:"ALARM_EMAIL_ADDRESS"})," and ",(0,s.jsx)(n.code,{children:"NOTE_EMAIL_ADDRESS"})," (and limiting with ",(0,s.jsx)(n.code,{children:"-a"})," and ",(0,s.jsx)(n.code,{children:"-R"})," ) and reporting data to telegraf (option ",(0,s.jsx)(n.code,{children:"-S"}),") may be present in the samples. Make this script executable (",(0,s.jsx)(n.code,{children:"chmod +x run_CLOUDNAME.sh"}),")."]}),"\n",(0,s.jsxs)(n.p,{children:["We wrap a loop around this in ",(0,s.jsx)(n.code,{children:"run_in_loop.sh"}),":"]}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-bash",children:'#!/bin/bash\n# run_in_loop.sh\nrm stop-os-hm 2>/dev/null\nwhile true; do\n  ./run_CLOUDNAME.sh -i 200\n  if test -e stop-os-hm; then break; fi\n  echo -n "Hit ^C to abort ..."\n  sleep 15; echo\ndone\n'})}),"\n",(0,s.jsxs)(n.p,{children:["Also make this executable (",(0,s.jsx)(n.code,{children:"chmod +x run_in_loop.sh"}),").\nTo run this automatically in a tmux window whenever the system starts, we follow the steps in the ",(0,s.jsx)(n.a,{href:"https://github.com/SovereignCloudStack/openstack-health-monitor/blob/main/startup/README.md",children:"startup README.md"})]}),"\n",(0,s.jsxs)(n.p,{children:["Change ",(0,s.jsx)(n.code,{children:"OS_CLOUD"})," in ",(0,s.jsx)(n.code,{children:"startup/run-apimon-in-tmux.sh"}),". (If you need to set ",(0,s.jsx)(n.code,{children:"OS_CACERT"}),", also add it in this file and pass it into the windows.)"]}),"\n",(0,s.jsx)(n.p,{children:"Activate everything:"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-bash",children:"mkdir -p ~/.config/systemd/user/\ncp -p startup/apimon.service ~/.config/systemd/user/\nsystemctl --user enable apimon\nsystemctl --user start apimon\nsudo loginctl enable-linger debian\ntmux attach -t oshealthmon\n"})}),"\n",(0,s.jsxs)(n.p,{children:["This assumes that you are using the user ",(0,s.jsx)(n.code,{children:"debian"})," for this monitoring and have checked out the repository at ",(0,s.jsx)(n.code,{children:"~/openstack-health-monitor/"}),". Adjust the paths and user name otherwise. (If for whatever reason you have chosen to install things as root, you will have to install the systemd service unit in the system paths and ensure it's not started too early in the boot process.)"]}),"\n",(0,s.jsx)(n.h3,{id:"changing-parameters-and-restarting",children:"Changing parameters and restarting"}),"\n",(0,s.jsxs)(n.p,{children:["If you want to change the parameters passed to ",(0,s.jsx)(n.code,{children:"api_monitor.sh"}),", you best do this by editing ",(0,s.jsx)(n.code,{children:"run_CLOUDNAME.sh"}),", potentially after testing it with one iteration before."]}),"\n",(0,s.jsxs)(n.p,{children:["To make the change effective, you can wait until the current 200 iterations are completed and the ",(0,s.jsx)(n.code,{children:"run_in_loop.sh"})," calls ",(0,s.jsx)(n.code,{children:"run_CLOUDNAME.sh"})," again. You can also hit ",(0,s.jsx)(n.code,{children:"^C"})," in the tmux window that has",(0,s.jsx)(n.code,{children:"api_monitor.sh"})," running. The script will then exit after the current iteration. Note that sending this interrupt is handled by the script, so it does still continue the current iteration and do all the cleanup work. However, you may interrupt an API call and thus cause a spurious error (which may in the worst case lead to a couple more spurious errors). If you want to avoid this, hit ",(0,s.jsx)(n.code,{children:"^C"})," during the wait/sleep phases of the script (after having done all the tests or after having completed the iteration). If you hit ",(0,s.jsx)(n.code,{children:"^C"})," twice, it will abort the the current iteration, but still try to clean up. Then the outer script will also exit and you have to restart by manually calling ",(0,s.jsx)(n.code,{children:"./run_in_loop.sh"})," again."]}),"\n",(0,s.jsxs)(n.p,{children:["You can also issue the ",(0,s.jsx)(n.code,{children:"systemctl --user stop apimon"})," command; it will basically do the same thing: Send ",(0,s.jsx)(n.code,{children:"^C"})," and then wait for everything to be completed and tear down the tmux session.\nAfter waiting for that to complete, you can start it again with ",(0,s.jsx)(n.code,{children:"systemctl --user start apimon"}),"."]}),"\n",(0,s.jsx)(n.h3,{id:"multiple-instances",children:"Multiple instances"}),"\n",(0,s.jsxs)(n.p,{children:["You can run multiple instances of ",(0,s.jsx)(n.code,{children:"api_monitor.sh"})," on the same driver VM. In this case, you should rename ",(0,s.jsx)(n.code,{children:"run_in_loop.sh"})," to e.g. ",(0,s.jsx)(n.code,{children:"run_in_loop_CLOUDNAME1.sh"})," and call ",(0,s.jsx)(n.code,{children:"run_CLOUDNAME1.sh"})," from there. Don't forget to adjust ",(0,s.jsx)(n.code,{children:"startup/run-apimon-in-tmux.sh"})," and ",(0,s.jsx)(n.code,{children:"startup/kill-apimon-in-tmux.sh"})," to start more windows."]}),"\n",(0,s.jsxs)(n.p,{children:["It is not recommended to run multiple instances against the same OpenStack project however. While the ",(0,s.jsx)(n.code,{children:"api_monitor.sh"})," script carefully keeps track of its own resources and avoids to delete things it has not created, this is not the case for the ",(0,s.jsx)(n.code,{children:"run_CLOUDNAME.sh"})," script, which is explicitly meant to identify anything in the target project that was created by a health monitor and clean it up. If it hits the resources that are currently in use by another health mon instance, this will create spurious errors. This will happen every ~200 iterations, so you could still have some short-term coexistence when you are performing debug operations."]}),"\n",(0,s.jsx)(n.h2,{id:"alarming-and-logs",children:"Alarming and Logs"}),"\n",(0,s.jsx)(n.h3,{id:"email",children:"eMail"}),"\n",(0,s.jsxs)(n.p,{children:["If wanted, the ",(0,s.jsx)(n.code,{children:"api_monitor.sh"})," can send statistics and error messages via email, so operator personnel is informed about the state of the monitoring. This email notification service potentially results in many emails; one error may produce several mails. So in case of a systematic problem, expect to receive dozens of mails per hour. This can be reduced a bit using the ",(0,s.jsx)(n.code,{children:"-a N"})," and ",(0,s.jsx)(n.code,{children:"-R"})," options. In order to enable sending emails from the driver VM, it needs to have ",(0,s.jsx)(n.code,{children:"postfix"})," (or another MTA) installed and configured and outgoing connections for eMail need to be allowed. Note that many operators prefer not to use the eMail notifications but rather rely on looking at the dashboards (see further down) regularly."]}),"\n",(0,s.jsxs)(n.p,{children:["Once you have configured ",(0,s.jsx)(n.code,{children:"postfix"}),", you can enable eMail notifications using the option ",(0,s.jsx)(n.code,{children:"-e"}),". Using it twice allows you to differentiate between notes (statistical summaries) and errors. If you want to send mails to more than one recipient, you can do so by passing ",(0,s.jsx)(n.code,{children:"ALARM_EMAIL_ADDRESSES"})," and ",(0,s.jsx)(n.code,{children:"NOTE_EMAIL_ADDRESSES"})," environment variables to ",(0,s.jsx)(n.code,{children:"api_monitor.sh"}),", e.g. by setting it in the ",(0,s.jsx)(n.code,{children:"run_CLOUDNAME.sh"}),"."]}),"\n",(0,s.jsx)(n.h3,{id:"log-files",children:"Log files"}),"\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.code,{children:"api_monitor.sh"})," writes a log file with the name ",(0,s.jsx)(n.code,{children:"APIMonitor_TIMESTAMP.log"}),". It contains a bit of information to see the progress of the script; more importantly, it logs every single openstack CLI call along with parameters and results. (",(0,s.jsx)(n.code,{children:"TIMESTAMP"})," is the Unix time, i.e. seconds since 1970-01-01 00:00:00 UTC.)"]}),"\n",(0,s.jsxs)(n.p,{children:["Note that ",(0,s.jsx)(n.code,{children:"api_monitor.sh"})," does take some care not to expose secrets -- since v1.99, it does also redact issued tokens (which would otherwise give you up to 24hrs of access). But the Log files still may contain moderately sensitive information, so we suggest to not share it with untrusted parties."]}),"\n",(0,s.jsxs)(n.p,{children:["The log file is written to the file system. After finishing the 200 iterations, the log file is compressed. If the environment variable ",(0,s.jsx)(n.code,{children:"SWIFTCONTAINER"})," has been set (in ",(0,s.jsx)(n.code,{children:"run_CLOUDNAME.sh"}),") when starting ",(0,s.jsx)(n.code,{children:"api_monitor.sh"}),". the log file will be uploaded to a container with that name if it exists and if the swift object storage service is supported by the cloud. So create the container (a bucket in S3 speak) before if you want to use this: ",(0,s.jsx)(n.code,{children:"export SWIFTCONTAINER=OSHM_Logs; openstack container create $SWIFTCONTAINER"})]}),"\n",(0,s.jsxs)(n.p,{children:["After the 200 iterations, a ",(0,s.jsx)(n.code,{children:".psv"})," file (pipe-separated values) is created ",(0,s.jsx)(n.code,{children:"Stats.STARTTIME-ENDTIME.psv"})," (with times as calendar dates) which contains a bit of statistics on the last 200 iterations. This one will also be uploaded to $SWIFTCONTAINER (if configured)."]}),"\n",(0,s.jsx)(n.h2,{id:"data-collection-and-dashboard",children:"Data collection and dashboard"}),"\n",(0,s.jsxs)(n.p,{children:["See ",(0,s.jsx)(n.a,{href:"https://github.com/SovereignCloudStack/openstack-health-monitor/blob/main/dashboard/README.md",children:"https://github.com/SovereignCloudStack/openstack-health-monitor/blob/main/dashboard/README.md"})]}),"\n",(0,s.jsx)(n.h3,{id:"telegraf",children:"Telegraf"}),"\n",(0,s.jsx)(n.p,{children:"To install telegraf on Debian 12, we need to add the apt repository provided by InfluxData:"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-bash",children:'sudo curl -fsSL https://repos.influxdata.com/influxdata-archive_compat.key -o /etc/apt/keyrings/influxdata-archive_compat.key\necho "deb [signed-by=/etc/apt/keyrings/influxdata-archive_compat.key] https://repos.influxdata.com/debian stable main" | sudo tee /etc/apt/sources.list.d/influxdata.list\nsudo apt update\nsudo apt -y install telegraf\n'})}),"\n",(0,s.jsxs)(n.p,{children:["In the config file ",(0,s.jsx)(n.code,{children:"/etc/telegraf/telegraf.conf"}),", we enable"]}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-toml",children:'[[inputs.influxdb_listener]]\n  service_address = ":8186"\n\n[[outputs.influxdb]]\n  urls = ["http://127.0.0.1:8086"]\n'})}),"\n",(0,s.jsxs)(n.p,{children:["and restart the service (",(0,s.jsx)(n.code,{children:"sudo systemctl restart telegraf"}),").\nEnable it on system startup: ",(0,s.jsx)(n.code,{children:"sudo systemctl enable telegraf"}),"."]}),"\n",(0,s.jsx)(n.h3,{id:"influxdb",children:"InfluxDB"}),"\n",(0,s.jsx)(n.p,{children:"We proceed to influxdb:"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-shell",children:"sudo apt-get install influxdb\n"})}),"\n",(0,s.jsxs)(n.p,{children:["In the configuration file ",(0,s.jsx)(n.code,{children:"/etc/influxdb/influxdb.conf"}),", ensure that the http interface on port 8086 is enabled."]}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-toml",children:'[http]\n  enabled = true\n  bind-address = ":8086"\n'})}),"\n",(0,s.jsxs)(n.p,{children:["Restart influxdb as needed with ",(0,s.jsx)(n.code,{children:"sudo systemctl restart influxdb"}),".\nAlso enable it on system startup: ",(0,s.jsx)(n.code,{children:"sudo systemctl enable influxdb"}),"."]}),"\n",(0,s.jsxs)(n.h3,{id:"add--s-cloudname-to-your-run_cloudnamesh-script",children:["Add ",(0,s.jsx)(n.code,{children:"-S CLOUDNAME"})," to your ",(0,s.jsx)(n.code,{children:"run_CLOUDNAME.sh"})," script"]}),"\n",(0,s.jsxs)(n.p,{children:["You need to tell the monitor that it should send data via telegraf to influxdb by adding the parameter ",(0,s.jsx)(n.code,{children:"-S CLOUDNAME"})," to the ",(0,s.jsx)(n.code,{children:"api_monitor.sh"})," call in ",(0,s.jsx)(n.code,{children:"run_CLOUDNAME.sh"}),". Restart it (see above) to make the change effective immediately (and not only after 200 iterations complete)."]}),"\n",(0,s.jsx)(n.h3,{id:"caddy-reverse-proxy",children:"Caddy (Reverse Proxy)"}),"\n",(0,s.jsxs)(n.p,{children:["We're going to deploy Grafana behind ",(0,s.jsx)(n.a,{href:"https://caddyserver.com/docs/",children:"Caddy"})," as a reverse proxy.\nCaddy is very easy to configure, comes with sensible defaults and can automatically provision TLS\ncertificates using Let's Encrypt."]}),"\n",(0,s.jsx)(n.h4,{id:"install-caddy",children:"Install Caddy"}),"\n",(0,s.jsxs)(n.p,{children:["We follow ",(0,s.jsx)(n.a,{href:"https://caddyserver.com/docs/install#debian-ubuntu-raspbian",children:"https://caddyserver.com/docs/install#debian-ubuntu-raspbian"})," to setup the stable APT repository:"]}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-shell",children:"sudo apt install -y debian-keyring debian-archive-keyring apt-transport-https curl\ncurl -1sLf 'https://dl.cloudsmith.io/public/caddy/stable/gpg.key' | sudo gpg --dearmor -o /usr/share/keyrings/caddy-stable-archive-keyring.gpg\ncurl -1sLf 'https://dl.cloudsmith.io/public/caddy/stable/debian.deb.txt' | sudo tee /etc/apt/sources.list.d/caddy-stable.list\n"})}),"\n",(0,s.jsx)(n.p,{children:"And install Caddy:"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-shell",children:"sudo apt update\nsudo apt install caddy\n"})}),"\n",(0,s.jsxs)(n.p,{children:["Ensure it's started and starts at boot with ",(0,s.jsx)(n.code,{children:"sudo systemctl enable --now caddy"}),"."]}),"\n",(0,s.jsx)(n.h4,{id:"allow-http-traffic-for-oshm-driver",children:"Allow HTTP traffic for oshm-driver"}),"\n",(0,s.jsxs)(n.p,{children:["Caddy needs TCP port ",(0,s.jsx)(n.code,{children:"80"})," opened to be able to process the Let's Encrypt HTTP challenge, so let's\nconfigure an appropriate security group for ",(0,s.jsx)(n.code,{children:"oshm-driver"}),":"]}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-shell",children:"openstack security group create http\nopenstack security group rule create --ingress --ethertype ipv4 --protocol tcp --dst-port 80 http\nopenstack server add security group oshm-driver http\n"})}),"\n",(0,s.jsx)(n.h4,{id:"configure-caddy",children:"Configure Caddy"}),"\n",(0,s.jsxs)(n.p,{children:["Create a file ",(0,s.jsx)(n.code,{children:"/etc/caddy/Caddyfile"})," with the following contents:"]}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-text",children:"https://health.YOURCLOUD.osba.sovereignit.cloud:3000 {\n    reverse_proxy localhost:3003\n}\n"})}),"\n",(0,s.jsxs)(n.p,{children:["Replace ",(0,s.jsx)(n.code,{children:"health.YOURCLOUD.osba.sovereignit.cloud"})," with your actual domain.\nYou can use a hostname of your liking, but Caddy will create TLS certificates for this host using\nthe HTTP challenge.\nThe ",(0,s.jsx)(n.code,{children:"sovereignit.cloud"})," domain is controlled by the SCS project team and has been used for a number\nof health mon instances."]}),"\n",(0,s.jsxs)(n.p,{children:["Reload Caddy with ",(0,s.jsx)(n.code,{children:"sudo systemctl reload caddy"}),". That's it."]}),"\n",(0,s.jsxs)(n.p,{children:["You should now be able to access ",(0,s.jsx)(n.code,{children:"https://health.YOURCLOUD.sovereignit.cloud:3000"})," and see a proxy error\npage because the Grafana service is not yet running (this is our next step).\nThe very first request will be a bit slower, because Caddy interacts with Let's Encrypt API to create\nthe TLS certificate behind the scenes."]}),"\n",(0,s.jsxs)(n.p,{children:["Caddy logs can be accessed with ",(0,s.jsx)(n.code,{children:"sudo journalctl -u caddy"}),"."]}),"\n",(0,s.jsx)(n.h3,{id:"grafana",children:"Grafana"}),"\n",(0,s.jsx)(n.h4,{id:"install-grafana",children:"Install Grafana"}),"\n",(0,s.jsxs)(n.p,{children:["We follow ",(0,s.jsx)(n.a,{href:"https://grafana.com/docs/grafana/latest/setup-grafana/installation/debian/",children:"https://grafana.com/docs/grafana/latest/setup-grafana/installation/debian/"})," and setup the stable APT repository:"]}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-shell",children:'mkdir -p /etc/apt/keyrings\nwget -q -O - https://apt.grafana.com/gpg.key | gpg --dearmor | sudo tee /etc/apt/keyrings/grafana.gpg > /dev/null\necho "deb [signed-by=/etc/apt/keyrings/grafana.gpg] https://apt.grafana.com stable main" | sudo tee -a /etc/apt/sources.list.d/grafana.list\n'})}),"\n",(0,s.jsx)(n.p,{children:"And install it:"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-shell",children:"sudo apt update\nsudo apt -y install grafana\n"})}),"\n",(0,s.jsx)(n.h4,{id:"basic-config",children:"Basic config"}),"\n",(0,s.jsxs)(n.p,{children:["The config file ",(0,s.jsx)(n.code,{children:"/etc/grafana/grafana.ini"})," needs some adjustments."]}),"\n",(0,s.jsx)(n.p,{children:"We're going to deploy Grafana behind a reverse proxy (Caddy) and configure it as such."}),"\n",(0,s.jsxs)(n.p,{children:["Therefore, in the ",(0,s.jsx)(n.code,{children:"[server]"})," section:"]}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-ini",children:"[server]\nprotocol = http\nhttp_addr = 127.0.0.1\nhttp_port = 3003\ndomain = health.YOURCLOUD.sovereignit.cloud\nroot_url = https://%(domain)s:3000/\n"})}),"\n",(0,s.jsxs)(n.p,{children:["Please replace ",(0,s.jsx)(n.code,{children:"health.YOURCLOUD.sovereignit.cloud"})," with your actual domain."]}),"\n",(0,s.jsxs)(n.p,{children:["Next, in the ",(0,s.jsx)(n.code,{children:"[security]"})," section, set:"]}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-ini",children:"[security]\nadmin_user = admin\nadmin_password = SOME_SECRET_PASS\nsecret_key = SOME_SECRET_KEY\ndata_source_proxy_whitelist = localhost:8088 localhost:8086\ncookie_secure = true\n"})}),"\n",(0,s.jsxs)(n.p,{children:["Please replace ",(0,s.jsx)(n.code,{children:"SOME_SECRET_PASS"})," and ",(0,s.jsx)(n.code,{children:"SOME_SECRET_KEY"})," with secure passwords (for example, you can use ",(0,s.jsx)(n.code,{children:"pwgen -s 20"}),")."]}),"\n",(0,s.jsxs)(n.p,{children:["Finally, in the ",(0,s.jsx)(n.code,{children:"[users]"})," section, set:"]}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-ini",children:"[users]\nallow_sign_up = false\nallow_org_create = false\n"})}),"\n",(0,s.jsx)(n.p,{children:"The configuration file contains secrets and should be protected such that only root and group grafana\ncan read it:"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-shell",children:"sudo chown root:grafana /etc/grafana/grafana.ini\nsudo chmod 0640 /etc/grafana/grafana.ini\n"})}),"\n",(0,s.jsxs)(n.p,{children:["We do the OIDC connection in the section ",(0,s.jsx)(n.code,{children:"[auth.github]"})," ",(0,s.jsx)(n.a,{href:"#github-oidc-integration",children:"later"}),"."]}),"\n",(0,s.jsxs)(n.p,{children:["We can now restart the service: ",(0,s.jsx)(n.code,{children:"sudo systemctl restart grafana-server"}),".\nBeing at it, also enable it on system startup: ",(0,s.jsx)(n.code,{children:"sudo systemctl enable grafana-server"}),"."]}),"\n",(0,s.jsxs)(n.p,{children:["You should now be able to access your dashboard on ",(0,s.jsx)(n.code,{children:"https://health.YOURCLOUD.sovereignit.cloud:3000"})," and log in\nvia the configured username ",(0,s.jsx)(n.code,{children:"admin"})," and your ",(0,s.jsx)(n.code,{children:"SOME_SECRET_PASS"})," password."]}),"\n",(0,s.jsx)(n.h4,{id:"enable-influx-database-in-grafana",children:"Enable influx database in grafana"}),"\n",(0,s.jsxs)(n.p,{children:["In the dashboard, go to Home, Connections, choose InfluxDB and Add new datasource. The defaults (database name, InfluxQL query language) work. You need to explicitly set the URL to ",(0,s.jsx)(n.code,{children:"http://localhost:8086"})," (despite this being the suggestion). Set the database name to ",(0,s.jsx)(n.code,{children:"telegraf"}),". Save&test should succeed."]}),"\n",(0,s.jsx)(n.h4,{id:"importing-the-dashboard",children:"Importing the dashboard"}),"\n",(0,s.jsxs)(n.p,{children:["Go to Home, Dashboards, New, Import.\nUpload the dashboard ",(0,s.jsx)(n.a,{href:"https://github.com/SovereignCloudStack/openstack-health-monitor/blob/main/dashboard/openstack-health-dashboard.json",children:".json file"})," from the repository, user the ",(0,s.jsx)(n.a,{href:"https://github.com/SovereignCloudStack/openstack-health-monitor/blob/main/dashboard/openstack-health-dashboard-10.json",children:"Grafana-10 variant"})," if you use Grafana 10 or newer."]}),"\n",(0,s.jsx)(n.p,{children:"In the dashboard, go to the settings gear wheel, variables, mycloud and add CLOUDNAME to the list of clouds that can be displayed. (There are some existing SCS clouds in that list.)\nSave."}),"\n",(0,s.jsx)(n.p,{children:"Now choose CLOUDNAME as cloud (top of the dashboard, rightmost dropdown for the mycloud filter variable)."}),"\n",(0,s.jsx)(n.h4,{id:"no-data-displayed",children:"No data displayed?"}),"\n",(0,s.jsx)(n.p,{children:'Sometimes, you may see a panel displaying "no data" despite the fact that the first full iteration of data has been sent to influx already. This may be a strange interaction between the browser and Grafana -- we have not analyzed whether that is a bug in Grafana.'}),"\n",(0,s.jsx)(n.p,{children:"One way to work around is to go into the setting of the panel (the three dots in the upper right corner), go to edit and start changing one aspect of the query. Apply. Change it back to the original. Apply. The data will appear. Save to be sure it's conserved."}),"\n",(0,s.jsx)(n.h4,{id:"dashboard-features",children:"Dashboard features"}),"\n",(0,s.jsx)(n.p,{children:"Look at the top line filters: You can filter to only see certain API calls or certain resources; the graphs are very crowded and filtering to better see what you want to focus on is very well intended."}),"\n",(0,s.jsx)(n.p,{children:"The first row of panels give a health impression; there are absolute numbers as well as percentage numbers and the panels turn amber and red in case you have too many errors. Note that the colors on the panels with absolute numbers can not take into account whether you look at just a few hours or at weeks. Accordingly, consider the colors a reasonable hint if things are green or not when looking at a ~24 hours interval. This limitation does not affect the colors on the percentage graph, obviously."}),"\n",(0,s.jsx)(n.p,{children:"You can change the time interval and zoom in also by marking an interval with the mouse. Zooming out to a few months can be a very useful feature to see trends and watch e.g. your API performance, your resource creation times or the benchmarks change over the long term."}),"\n",(0,s.jsx)(n.h4,{id:"github-oidc-integration",children:"GitHub OIDC Integration"}),"\n",(0,s.jsx)(n.p,{children:"The SCS providers do allow all GitHub users that belong to the SovereignCloudStack organization to get Viewer\naccess to the dashboards.\nThis allows to exchange experience and to get a feeling for the achievable stability.\n(Hint: A single digit number of API call fails per week and no other failures is achievable on loaded clouds.)"}),"\n",(0,s.jsxs)(n.p,{children:["OIDC integration is achieved by adjusting the ",(0,s.jsx)(n.code,{children:"[auth.github]"})," section in ",(0,s.jsx)(n.code,{children:"/etc/grafana/grafana.ini"})," as follows:"]}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-ini",children:'[auth.github]\nenabled = true\nclient_id = YOUR_CLIENT_ID\nclient_secret = YOUR_CLIENT_SECRET\nallowed_organizations = ["SovereignCloudStack"]\nrole_attribute_path = "\'Viewer\'"\nallow_assign_grafana_admin = false\nskip_org_role_sync = true\n'})}),"\n",(0,s.jsxs)(n.p,{children:["This config maps all users to the ",(0,s.jsx)(n.code,{children:"Viewer"})," role regardless of their role in the GitHub Org.\nPlease replace ",(0,s.jsx)(n.code,{children:"YOUR_CLIENT_ID"})," and ",(0,s.jsx)(n.code,{children:"YOUR_CLIENT_SECRET"})," with the OAuth2 credentials that the SCS Org GitHub admins\nprovided to you.\nFinally, don't forgot to restart Grafana with ",(0,s.jsx)(n.code,{children:"sudo systemctl restart grafana-server"})," after adjusting the config."]}),"\n",(0,s.jsxs)(n.p,{children:["More information can be found in the ",(0,s.jsx)(n.a,{href:"https://grafana.com/docs/grafana/latest/setup-grafana/configure-security/configure-authentication/github/",children:"Grafana documentation for GitHub OAuth2"}),"."]}),"\n",(0,s.jsx)(n.h2,{id:"maintenance",children:"Maintenance"}),"\n",(0,s.jsx)(n.p,{children:"The driver VM is a snowflake: A manually set up system (unless you automate all the above steps, which is possible of course) that holds data and is long-lived. As such it's important to be maintained."}),"\n",(0,s.jsx)(n.h3,{id:"unattended-upgrades",children:"Unattended upgrades"}),"\n",(0,s.jsxs)(n.p,{children:["It is recommended to ensure maintenance updates are deployed automatically. These are unlikely to negatively impact the openstack-health-monitor. See ",(0,s.jsx)(n.a,{href:"https://wiki.debian.org/UnattendedUpgrades",children:"https://wiki.debian.org/UnattendedUpgrades"}),". If you decide against unattended upgrades, it is recommended to install updates manually regularly and especially watch out for issues that affect the services that are exposed to the world: sshd (port 22) and Caddy/Grafana (port 3000)."]}),"\n",(0,s.jsxs)(n.p,{children:["If you use ",(0,s.jsx)(n.code,{children:"unattended-upgrades"}),", you should review your settings in ",(0,s.jsx)(n.code,{children:"/etc/apt/apt.conf.d/50unattended-upgrades"}),",\nespecially ",(0,s.jsx)(n.code,{children:"Unattended-Upgrade::Origins-Pattern"}),". It controls which packages are upgraded. If you want Caddy to be\npart of the automated updates, add an entry like the following:"]}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-text",children:'Unattended-Upgrade::Origins-Pattern {\n    // ...\n    "origin=cloudsmith/caddy/stable";\n};\n'})}),"\n",(0,s.jsxs)(n.p,{children:["(This corresponds to ",(0,s.jsx)(n.code,{children:"o=cloudsmith/caddy/stable"})," in the output of ",(0,s.jsx)(n.code,{children:"apt-cache policy"}),")."]}),"\n",(0,s.jsx)(n.h3,{id:"sshd-setup",children:"sshd setup"}),"\n",(0,s.jsxs)(n.p,{children:["If you already use SSH keys to sign in to the driver VM, consider setting the following in your ",(0,s.jsx)(n.code,{children:"/etc/ssh/sshd_config"}),"\nif not already set:"]}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-text",children:"PasswordAuthentication no\n"})}),"\n",(0,s.jsxs)(n.p,{children:["Debian's ",(0,s.jsx)(n.code,{children:"openssh-server"}),", by default, is also very open about its version, so you might consider disabling this via:"]}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-text",children:"DebianBanner no\n"})}),"\n",(0,s.jsx)(n.h3,{id:"updating-openstack-health-monitor",children:"Updating openstack-health-monitor"}),"\n",(0,s.jsxs)(n.p,{children:["You can just do a ",(0,s.jsx)(n.code,{children:"git update"})," in the ",(0,s.jsx)(n.code,{children:"openstack-health-monitor"})," directory to get the latest improvements. Note that these will only become effective after the 200 iterations have completed. You can speed this up by injecting a ",(0,s.jsx)(n.code,{children:"^C"}),", see above in the restart section."]}),"\n",(0,s.jsx)(n.h3,{id:"backup",children:"Backup"}),"\n",(0,s.jsxs)(n.p,{children:["The system holds two things that you might consider valuable for long-term storage:\n(1) The log files. These are compressed and uploaded to object storage if you enable the ",(0,s.jsx)(n.code,{children:"SWIFTCONTAINER"})," setting, which probably means that these do not need any additional backing up then.\n(2) The influx time series data. Back up the data in ",(0,s.jsx)(n.code,{children:"/var/lib/influxdb"}),"."]}),"\n",(0,s.jsxs)(n.p,{children:["Obviously, if you want to recover quickly from a crash, you might consider to also back up telegraf, influx and grafana config files as well as the edited startup scripts, ",(0,s.jsx)(n.code,{children:"clouds.yaml"}),", etc. Be careful not to expose sensitive data by granting too generous access to your backed up files."]}),"\n",(0,s.jsx)(n.h2,{id:"troubleshooting",children:"Troubleshooting"}),"\n",(0,s.jsx)(n.h3,{id:"debugging-issues",children:"Debugging issues"}),"\n",(0,s.jsx)(n.p,{children:"In case there is trouble with your cloud, the normal course of action to analyze is as follows:"}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsx)(n.li,{children:"Look at the dashboard (see above)"}),"\n",(0,s.jsxs)(n.li,{children:["Connect to the driver VM and attach to the tmux session and look at the console output of ",(0,s.jsx)(n.code,{children:"api_monitor.sh"})]}),"\n",(0,s.jsx)(n.li,{children:"Analyze the logfile (locally on the driver VM or grab it from the object storage)"}),"\n"]}),"\n",(0,s.jsx)(n.h3,{id:"analyzing-failures",children:"Analyzing failures"}),"\n",(0,s.jsxs)(n.p,{children:["When VM instances are created successfully, but then end up in ",(0,s.jsx)(n.code,{children:"ERROR"})," state, the ",(0,s.jsx)(n.code,{children:"api_monitor.sh"})," does an explicit ",(0,s.jsx)(n.code,{children:"openstack server show"}),", so you will find some details in the tmux session, in the alarm emails (if you use those) and in the log files."]}),"\n",(0,s.jsxs)(n.p,{children:["Sometimes the VMs end up being ",(0,s.jsx)(n.code,{children:"ACTIVE"})," as wanted but then they can't be accessed via ssh. More often than not, this is a problem with meta-data service on a compute host. Without metadata, not ssh key is injected and login will fail."]}),"\n",(0,s.jsxs)(n.p,{children:["To gather more details, you can look at the console output ",(0,s.jsx)(n.code,{children:"openstack console log show VM"})," (where ",(0,s.jsx)(n.code,{children:"VM"})," is the name of the uuid of the affected VM instance). The cloud-init output is often enough to see what has gone wrong. You can log in to the VMs: The jumphosts are directly accessible via ",(0,s.jsx)(n.code,{children:"ssh -i APIMonitor_XXXXX_JH.pem debian@FIP"}),", whereas the JumpHost does port forwarding to the other VMs that don't have their own floating IP address: ",(0,s.jsx)(n.code,{children:"ssh -i APIMonitor_XXXXX_VM.pem -p 222 debian@FIP"}),". Replace ",(0,s.jsx)(n.code,{children:"XXXXX"})," with the number in your current APIMonitor prefix, ",(0,s.jsx)(n.code,{children:"FIP"})," with the floating IP address of the responsible JumpHost and ",(0,s.jsx)(n.code,{children:"debian"})," with the user name used by the images you boot. Use ",(0,s.jsx)(n.code,{children:"223"})," to connect to the second VM in the network, ",(0,s.jsx)(n.code,{children:"224"})," the third etc."]}),"\n",(0,s.jsxs)(n.p,{children:["When logged in, look at ",(0,s.jsx)(n.code,{children:"/var/log/cloud-init-output.log"})," and ",(0,s.jsx)(n.code,{children:"/var/log/cloud-init.log"}),". You can find the metadata in ",(0,s.jsx)(n.code,{children:"/var/lib/cloud/instance/"}),"."]}),"\n",(0,s.jsxs)(n.p,{children:["You will not have much time to look around -- the still running ",(0,s.jsx)(n.code,{children:"api_monitor.sh"})," script does continue and clean things up again. So you might want to suspend it with ",(0,s.jsx)(n.code,{children:"^Z"})," (and continue it later with ",(0,s.jsx)(n.code,{children:"fg"}),"). Another option is to not stop the regular monitoring, but start a second instance manually; see above notes for running multiple instances though. If you start a second instance manually against the same project, do NOT use the ",(0,s.jsx)(n.code,{children:"run_CLOUDNAME.sh"})," script as it would do cleanup against the running instance, but rather copy the ",(0,s.jsx)(n.code,{children:"api_monitor.sh"})," command line from the bottom (without the ",(0,s.jsx)(n.code,{children:"exec"}),"), reduce the iterations to a few (unless you need a lot to trigger the issue again) and attach ",(0,s.jsx)(n.code,{children:"-w -1"})," to make the script stop its operation (and wait for Enter) once it hits an error. Of course, you still will face cleanup when the continuing main script hits its 200th iteration and you have chosen to run this second instance against the same project in the same cloud. After analyzing, do not forget to go back to the tmux window where the stopped script is running and do hit Enter, so it can continue and do its cleanup work."]}),"\n",(0,s.jsx)(n.h3,{id:"cleaning-things-up",children:"Cleaning things up"}),"\n",(0,s.jsx)(n.p,{children:"If you are unlucky, the script fails to clean something up. A volume may not have been named (because of a cinder failure) or all the logic may have gone wrong, e.g. the heuristic to avoid leaking floating IPs. You can try to clean this up using the normal openstack commands (or horizon dashboard)."}),"\n",(0,s.jsx)(n.p,{children:"There are a few things that may need support from a cloud admin:"}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:["Volumes may end up permanently in a ",(0,s.jsx)(n.code,{children:"deleting"})," or ",(0,s.jsx)(n.code,{children:"reserved"})," state or may be ",(0,s.jsx)(n.code,{children:"in-use"}),", attached to a VM that has long gone. The admin needs to set the state to ",(0,s.jsx)(n.code,{children:"error"})," and then delete them."]}),"\n",(0,s.jsxs)(n.li,{children:["Loadbalancers may end up in a ",(0,s.jsx)(n.code,{children:"PENDING_XXX"})," state (",(0,s.jsx)(n.code,{children:"XXX"})," being ",(0,s.jsx)(n.code,{children:"CREATE"}),", ",(0,s.jsx)(n.code,{children:"UPDATE"})," or ",(0,s.jsx)(n.code,{children:"DELETE"}),") without ever changing. This also needs the cloud admin to set the status to ",(0,s.jsx)(n.code,{children:"ERROR"}),", so it can be cleaned up. amphorae are more prone to this than ovn LBs."]}),"\n"]}),"\n",(0,s.jsx)(n.p,{children:"More like these may happen, but those two are the only ones that have been observed to happen occasionally. Some services seem to be less robust than others against an event in the event queue (rabbitmq) being lost or an connection to be interrupted."}),"\n",(0,s.jsx)(n.p,{children:(0,s.jsxs)(n.em,{children:["The source of this document can be found in the ",(0,s.jsx)(n.a,{href:"https://raw.githubusercontent.com/SovereignCloudStack/openstack-health-monitor/main/docs/Debian12-Install.md",children:"SovereignCloudStack/openstack-health-monitor"})," repository."]})}),"\n",(0,s.jsx)(n.p,{children:(0,s.jsx)(n.em,{children:"Author: SCS Community, License: CC by Attribution 4.0 International"})})]})}function h(e={}){const{wrapper:n}={...(0,a.R)(),...e.components};return n?(0,s.jsx)(n,{...e,children:(0,s.jsx)(c,{...e})}):c(e)}},28453:(e,n,t)=>{t.d(n,{R:()=>i,x:()=>r});var o=t(96540);const s={},a=o.createContext(s);function i(e){const n=o.useContext(a);return o.useMemo((function(){return"function"==typeof e?e(n):{...n,...e}}),[n,e])}function r(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(s):e.components||s:i(e.components),o.createElement(a.Provider,{value:n},e.children)}}}]);